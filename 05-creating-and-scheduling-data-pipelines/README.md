# Project05 : Creating and Scheduling data pipelines
## What is this?
 This is a automate data pipeline to do process data from dataset by using Airflow. 

## How to run this code?
1. Go to 5-creating-and-scheduling-data-pipelines.
2. Run command "docker compose up" to do install Airflow.
3. Go to port and open port 8080 to do open Airflow Application.
4. Go to Dag Floder, Is in DAG if you want to chang schedule or process collect data, You can edit in etl.py.
5. When finished, You can see job in Airflow Application.